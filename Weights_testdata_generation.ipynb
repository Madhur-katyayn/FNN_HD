{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iSrteUNHysvr"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Converting to fixed point\n",
    "def convert_to_fixed_point_for_weights(arr, size, width, after_decimal, part_number, part_width):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint(number, width, after_decimal,part_number,part_width)\n",
    "    elif(number<0):\n",
    "      binary_number=binary_number+negative_num_to_fixedpoint(abs(number), width, after_decimal, part_number,part_width)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Converting to fixed point\n",
    "def convert_to_fixed_point_for_bias(arr, size, width, after_decimal, part_number, part_width):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    part_number_temp=part_number[i]\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint(number, width, after_decimal,part_number_temp,part_width)\n",
    "    elif(number<0):\n",
    "      binary_number=binary_number+negative_num_to_fixedpoint(abs(number), width, after_decimal, part_number_temp,part_width)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_num_to_fixedpoint(number, width, after_decimal, part_number,part_width):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  # binary_array=[]\n",
    "  # decimal_num=number\n",
    "  s=bin(new_num)\n",
    "  s1 = s[2:]\n",
    "  lenght_binary_string=len(s1)\n",
    "  temp_str='0'\n",
    "  k=0\n",
    "  while(k<(width-lenght_binary_string-1)):\n",
    "    temp_str=temp_str+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_binary_string):\n",
    "    temp_str=temp_str+s1[k]\n",
    "    k=k+1\n",
    "  part_number_binary_temp=bin(part_number)\n",
    "  part_number_binary=part_number_binary_temp[2:]\n",
    "  lenght_part_number_binary=len(part_number_binary)\n",
    "  temp_str_1=''\n",
    "  k=0\n",
    "  while(k<(part_width-lenght_part_number_binary)):\n",
    "    temp_str_1=temp_str_1+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_part_number_binary):\n",
    "    temp_str_1=temp_str_1+part_number_binary[k]\n",
    "    k=k+1\n",
    "  temp_str=temp_str+temp_str_1\n",
    "  # binary_array.append(temp_str)\n",
    "\n",
    "  return temp_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_num_to_fixedpoint(number, width, after_decimal, part_number, part_width):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  if(new_num==0):\n",
    "    temp_str=positive_num_to_fixedpoint(number, width, after_decimal, part_number, part_width)\n",
    "  else:\n",
    "      two_s_complement=2**(width-1)-new_num\n",
    "      # binary_array=[]\n",
    "      # decimal_num=number\n",
    "      s=bin(two_s_complement)\n",
    "      s1 = s[2:]\n",
    "      lenght_binary_string=len(s1)\n",
    "      temp_str='1'\n",
    "      k=0\n",
    "      while(k<(width-lenght_binary_string-1)):\n",
    "        temp_str=temp_str+'1'\n",
    "        k=k+1\n",
    "      k=0\n",
    "      while(k<lenght_binary_string):\n",
    "        temp_str=temp_str+s1[k]\n",
    "        k=k+1\n",
    "\n",
    "      part_number_binary_temp=bin(part_number)\n",
    "      part_number_binary=part_number_binary_temp[2:]\n",
    "      lenght_part_number_binary=len(part_number_binary)\n",
    "      temp_str_1=''\n",
    "      k=0\n",
    "      while(k<(part_width-lenght_part_number_binary)):\n",
    "        temp_str_1=temp_str_1+'0'\n",
    "        k=k+1\n",
    "      k=0\n",
    "      while(k<lenght_part_number_binary):\n",
    "        temp_str_1=temp_str_1+part_number_binary[k]\n",
    "        k=k+1\n",
    "      temp_str=temp_str+temp_str_1\n",
    "  # binary_array.append(temp_str)\n",
    "  return temp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XY3qKmEMyvzS",
    "outputId": "1b21ccaa-4285-4675-da2d-8a5e3f2c0fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.7039 - accuracy: 0.7714 - val_loss: 1.5243 - val_accuracy: 0.9417\n",
      "Epoch 2/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.5465 - accuracy: 0.9194 - val_loss: 1.4999 - val_accuracy: 0.9667\n",
      "Epoch 3/30\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 1.5298 - accuracy: 0.9347 - val_loss: 1.5044 - val_accuracy: 0.9617\n",
      "Epoch 4/30\n",
      "1857/1857 [==============================] - 6s 3ms/step - loss: 1.5203 - accuracy: 0.9434 - val_loss: 1.4940 - val_accuracy: 0.9700\n",
      "Epoch 5/30\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 1.5137 - accuracy: 0.9491 - val_loss: 1.4984 - val_accuracy: 0.9617\n",
      "Epoch 6/30\n",
      "1857/1857 [==============================] - 3s 2ms/step - loss: 1.5087 - accuracy: 0.9543 - val_loss: 1.4990 - val_accuracy: 0.9633\n",
      "Epoch 7/30\n",
      "1857/1857 [==============================] - 5s 3ms/step - loss: 1.5062 - accuracy: 0.9561 - val_loss: 1.4909 - val_accuracy: 0.9717\n",
      "Epoch 8/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.5027 - accuracy: 0.9598 - val_loss: 1.4975 - val_accuracy: 0.9650\n",
      "Epoch 9/30\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.5004 - accuracy: 0.9620 - val_loss: 1.4971 - val_accuracy: 0.9617\n",
      "Epoch 10/30\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 1.4986 - accuracy: 0.9636 - val_loss: 1.4900 - val_accuracy: 0.9733\n",
      "Epoch 11/30\n",
      "1857/1857 [==============================] - 6s 3ms/step - loss: 1.4967 - accuracy: 0.9653 - val_loss: 1.5014 - val_accuracy: 0.9583\n",
      "Epoch 12/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4944 - accuracy: 0.9675 - val_loss: 1.4941 - val_accuracy: 0.9650\n",
      "Epoch 13/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4941 - accuracy: 0.9678 - val_loss: 1.4932 - val_accuracy: 0.9683\n",
      "Epoch 14/30\n",
      "1857/1857 [==============================] - 8s 4ms/step - loss: 1.4931 - accuracy: 0.9687 - val_loss: 1.4937 - val_accuracy: 0.9650\n",
      "Epoch 15/30\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.4922 - accuracy: 0.9695 - val_loss: 1.4904 - val_accuracy: 0.9733\n",
      "Epoch 16/30\n",
      "1857/1857 [==============================] - 5s 3ms/step - loss: 1.4910 - accuracy: 0.9707 - val_loss: 1.4915 - val_accuracy: 0.9700\n",
      "Epoch 17/30\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4894 - accuracy: 0.9723 - val_loss: 1.4902 - val_accuracy: 0.9700\n",
      "Epoch 18/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4899 - accuracy: 0.9717 - val_loss: 1.4903 - val_accuracy: 0.9683\n",
      "Epoch 19/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4885 - accuracy: 0.9730 - val_loss: 1.4872 - val_accuracy: 0.9767\n",
      "Epoch 20/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4879 - accuracy: 0.9736 - val_loss: 1.4890 - val_accuracy: 0.9750\n",
      "Epoch 21/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4874 - accuracy: 0.9742 - val_loss: 1.4881 - val_accuracy: 0.9750\n",
      "Epoch 22/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4866 - accuracy: 0.9750 - val_loss: 1.4853 - val_accuracy: 0.9783\n",
      "Epoch 23/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4860 - accuracy: 0.9754 - val_loss: 1.4929 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4864 - accuracy: 0.9749 - val_loss: 1.4961 - val_accuracy: 0.9650\n",
      "Epoch 25/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4854 - accuracy: 0.9761 - val_loss: 1.4958 - val_accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "1857/1857 [==============================] - 10s 5ms/step - loss: 1.4841 - accuracy: 0.9774 - val_loss: 1.4892 - val_accuracy: 0.9717\n",
      "Epoch 27/30\n",
      "1857/1857 [==============================] - 4s 2ms/step - loss: 1.4844 - accuracy: 0.9770 - val_loss: 1.4927 - val_accuracy: 0.9683\n",
      "Epoch 28/30\n",
      "1857/1857 [==============================] - 3s 1ms/step - loss: 1.4834 - accuracy: 0.9781 - val_loss: 1.4932 - val_accuracy: 0.9667\n",
      "Epoch 29/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4836 - accuracy: 0.9778 - val_loss: 1.4974 - val_accuracy: 0.9633\n",
      "Epoch 30/30\n",
      "1857/1857 [==============================] - 2s 1ms/step - loss: 1.4832 - accuracy: 0.9782 - val_loss: 1.4903 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ff1bb4250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  # keras.layers.Conv2D(filters=1, kernel_size=(3, 3), activation='relu'),\n",
    "  # keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(40,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=30,\n",
    "  validation_split=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfA_3scon3Nq",
    "outputId": "9ee21b05-23c9-49fa-88ad-73ca206941d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Reshape object at 0x0000024FCC6F1A00>\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x0000024FCC6F1E50>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000024FCC6F1B20>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000024FCC6E92E0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000024FCC6E95E0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000024FCC6E9700>\n"
     ]
    }
   ],
   "source": [
    "for item in model.layers:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"weights_and_biases.mif\", \"w\")\n",
    "layers = [784, 40, 10, 10,10]\n",
    "for_bias= [0, 40, 50, 60,70]\n",
    "data_width=16\n",
    "after_decimal=14\n",
    "k = 0\n",
    "part_width=7\n",
    "while(k<4):\n",
    "    layer_weights = []\n",
    "    layer_weights = model.layers[2+k].get_weights()[0]\n",
    "    j=0\n",
    "    layer_1_bias = model.layers[2+k].get_weights()[1] \n",
    "    part_number_bias=np.arange(for_bias[k],for_bias[k+1],1)\n",
    "    layer_1_bias_binary = convert_to_fixed_point_for_bias(layer_1_bias, layers[k+1], data_width, after_decimal, part_number_bias, part_width)\n",
    "    while(j<layers[k+1]):\n",
    "        l1_n1_w=[]\n",
    "        i=0\n",
    "        while(i<layers[k]):\n",
    "            l1_n1_w.append(layer_weights[i][j])\n",
    "            i=i+1\n",
    "        l1_n1_w_binary = convert_to_fixed_point_for_weights(l1_n1_w, layers[k], data_width, after_decimal,part_number_bias[j],part_width)\n",
    "\n",
    "        textfile = open(\"weights_and_biases.mif\", \"a\")\n",
    "        for element in l1_n1_w_binary:\n",
    "            textfile.write(element + \"\\n\")\n",
    "        textfile.close()\n",
    "        layer_1_bias_binary_n = layer_1_bias_binary[j]\n",
    "        textfile = open(\"weights_and_biases.mif\", \"a\")\n",
    "        textfile.write(layer_1_bias_binary_n + \"\\n\")\n",
    "        textfile.close()\n",
    "        j=j+1\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_num_to_fixedpoint_for_image(number, width, after_decimal):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  # binary_array=[]\n",
    "  # decimal_num=number\n",
    "  s=bin(new_num)\n",
    "  s1 = s[2:]\n",
    "  lenght_binary_string=len(s1)\n",
    "  temp_str='0'\n",
    "  k=0\n",
    "  while(k<(width-lenght_binary_string-1)):\n",
    "    temp_str=temp_str+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_binary_string):\n",
    "    temp_str=temp_str+s1[k]\n",
    "    k=k+1\n",
    "  # binary_array.append(temp_str)\n",
    "\n",
    "  return temp_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fixed_point_for_image(arr, size, width, after_decimal):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint_for_image(number, width, after_decimal)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_convert_to_fixed_point(image, no_of_inputs, word_width, after_decimal):\n",
    "    i=0\n",
    "    j=0\n",
    "    k=0\n",
    "    flatten_image=np.zeros(784)\n",
    "    while(i<28):\n",
    "        j=0\n",
    "        while(j<28):\n",
    "            flatten_image[k]=image[i][j]\n",
    "            j=j+1\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "    image_in_fixed_point=convert_to_fixed_point_for_image(flatten_image,no_of_inputs,word_width,after_decimal)\n",
    "    return image_in_fixed_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "i=0\n",
    "textfile = open(\"input_test_data.mif\", \"w\")\n",
    "while(i<8):\n",
    "    j=1\n",
    "    while(j<21):\n",
    "        image_array = image.imread(\"data_\"+str(i)+\" (\"+str(j)+\").png\")\n",
    "        image_in_fixed_point=flatten_and_convert_to_fixed_point(image_array,784,16,14)\n",
    "        for element in image_in_fixed_point:\n",
    "            textfile.write(element + \"\\n\")\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    \n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "# load image as pixel array\n",
    "i=0\n",
    "imagefile = 't10k-images.idx3-ubyte'\n",
    "imagearray = idx2numpy.convert_from_file(imagefile)\n",
    "imagearray_part=imagearray[0:150]\n",
    "textfile = open(\"input_test_data_full.mif\", \"w\")\n",
    "while(i<150):\n",
    "    image_in_fixed_point=flatten_and_convert_to_fixed_point(imagearray_part[i],784,16,14)\n",
    "    for element in image_in_fixed_point:\n",
    "        textfile.write(element + \"\\n\")\n",
    "    i=i+1\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 't10k-labels.idx1-ubyte'\n",
    "label_array = idx2numpy.convert_from_file(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array_part=label_array[0:150]\n",
    "textfile = open(\"actual_input.txt\", \"w\")\n",
    "for element in label_array_part:\n",
    "        textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Tensorflowmodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
